---
bibliography: references.bib
categories:
- AI
- Results Metrics
date: 2024-01-13
description: 'A note on different loss functions.

  '
google-scholar: true
image: activation.jpeg
title: Notes on Results Metrics
---


<!-- In a recent paper that has attracted the interest of popular media as well, Fabio Urbina and colleagues examined the use (or rather, the abuse) of computational chemistry models of toxicity for generating toxic compounds and potential chemical agent candidates.[@urbina2022dual] Urbina and colleagues conclude that -->

<!-- > By going as close as we dared, we have still crossed a grey moral boundary, demonstrating that it is possible to design virtual potential toxic molecules without much in the way of effort, time or computational resources. -->
Results


# Background

# Why different result metrics

The purpose of loss function is to quantify the error between the output of an algorithm and the given target value.

>Let's say that I have 100 pieces of something and I want the algorithm to predict the number of pieces available. Here, 
100 pieces are the ground truth or the target value. Now, if the algorithm predicts that there are only 90 pieces, there is a loss or error of 10 pieces.

# Types of Metrics
- Precision :  Accuracy of positive prediction of all items classified as positive, how many were actually positive
            True Positive/ (True Positive + False Positive)
- Recall : Sensitivity or True Positive Rate. Of all the actual positive instances, how many were correctly identified by the model
            True Positive/ (True Positive + False Negative)

# Thoughts:

